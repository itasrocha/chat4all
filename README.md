# Chat4All - Sistema de Mensageria Distribu√≠da

Plataforma de comunica√ß√£o ub√≠qua (API) capaz de rotear mensagens e arquivos entre usu√°rios em m√∫ltiplas plataformas (mock) e entre clientes internos. Arquitetura orientada a eventos e micro-servi√ßos, projetada para escalabilidade horizontal e alta disponibilidade. Projeto desenvolvido na disciplina de sistemas distribu√≠dos.

---

## üèó Arquitetura & Decis√µes de Projeto

O sistema foi arquitetado para priorizar **Disponibilidade** e **Toler√¢ncia a Particionamento** (AP no Teorema CAP) na ingest√£o de mensagens, garantindo que o sistema aceite escritas mesmo sob alta carga. Para a leitura, buscamos **Consist√™ncia Causal** para preservar a ordem l√≥gica das mensagens.

![Arquitetura](screenshots/arquitetura.png)

### 1. Arquitetura Orientada a Eventos

Utilizamos o **Apache Kafka** como espinha dorsal do sistema. Isso desacopla os produtores (API) dos consumidores (Persist√™ncia, Notifica√ß√µes, Integra√ß√µes), permitindo que cada servi√ßo escale independentemente.

- **Ingest√£o Ass√≠ncrona:** A API apenas valida e publica o evento `message.created`. O processamento pesado ocorre em background.
- **Garantia de Entrega:** Adotamos a sem√¢ntica de entrega **"At-least-once"**, tratando duplicatas na ponta do consumidor (`ingestion-service`) atrav√©s de idempot√™ncia.

### 2. Microsservi√ßos

O backend foi dividido em servi√ßos aut√¥nomos com responsabilidades estritas:

| Servi√ßo                  | Papel no Sistema Distribu√≠do                                                       | Tecnologia                 |
| :----------------------- | :--------------------------------------------------------------------------------- | :------------------------- |
| **API Service**          | **Gateway de Entrada**. Stateless. Gerencia autentica√ß√£o e valida√ß√£o de schema.    | FastAPI / gRPC Client      |
| **Ingestion Worker**     | **Persist√™ncia**. Consome do Kafka e grava no banco de alta vaz√£o.                 | Python Consumer / ScyllaDB |
| **Fanout Service**       | **Roteamento**. Distribui mensagens para filas espec√≠ficas (WhatsApp, Push, Web).  | Python Kafka Streams       |
| **Delivery Worker**      | **Entrega Online**. Ponte entre o Kafka e o Redis PubSub para usu√°rios conectados. | Python Consumer / Redis    |
| **Notification Service** | **Entrega Offline**. Envia Push Notifications para usu√°rios desconectados.         | Python Consumer            |
| **Status Service**       | **Ciclo de Vida**. Atualiza status de entrega (SENT -> DELIVERED -> READ).         | Python Consumer            |
| **Connectors (Mock)**    | **Integra√ß√£o**. Simula envio/recebimento via WhatsApp e Instagram.                 | Python / Kafka Producer    |
| **Metadata Service**     | **Fonte da Verdade**. Gerencia estados globais e sequenciamento.                   | gRPC Server / PostgreSQL   |
| **Socket Gateway**       | **Real-time**. Mant√©m conex√µes persistentes com clientes (Stateful na borda).      | FastAPI / Redis PubSub     |

### 3. Gerenciamento de Dados & Consist√™ncia

Adotamos **Persist√™ncia Poliglota** para otimizar diferentes padr√µes de acesso:

- **ScyllaDB (Wide-Column):** Usado para o hist√≥rico de mensagens. Escolhido pela capacidade de escrita massiva e particionamento horizontal.
- **PostgreSQL (Relacional):** Usado para dados com integridade referencial complexa (Usu√°rios, Grupos).
- **Redis (In-Memory Key/Value):**
  - **Cache:** Armazena sess√µes de usu√°rio.
  - **Pub/Sub:** Canal de distribui√ß√£o para mensagens em tempo real entre inst√¢ncias do Gateway.
- **Atomic Sequencer (Consist√™ncia):** Para garantir a ordena√ß√£o global das mensagens em um ambiente distribu√≠do, implementamos um gerador de sequ√™ncia at√¥mico no PostgreSQL, acessado via gRPC pelo `ingestion-service`.

---

## üõ† Tech Stack

- **Linguagem:** Python 3.11 (Type-safe)
- **Comunica√ß√£o S√≠ncrona:** gRPC + Protocol Buffers
- **Message Broker:** Apache Kafka 3.7
- **Bancos de Dados:** ScyllaDB (NoSQL), PostgreSQL 15
- **Cache & PubSub:** Redis Cluster 7.0
- **Storage:** MinIO (S3 Compatible)
- **Infraestrutura:** Docker Compose, Nginx

---

## üöÄ Como Executar

Requisitos: **Docker** e **Make**.

1.  **Clone o projeto:**

    ```bash
    git clone https://github.com/itasrocha/chat4all
    cd chat4all
    ```

2.  **Compile os contratos (Protobuf):**
    Necess√°rio para gerar o c√≥digo de comunica√ß√£o entre servi√ßos.

    ```bash
    make build
    ```

3.  **Inicie o Ambiente:**
    Este comando sobe toda a topologia (Kafka, Bancos, Servi√ßos) em containers.

    ```bash
    make up
    ```

4.  **Rode os testes:**
    ```bash
    make test
    ```
