# infra/local/docker-compose.yml
services:
  # --- INFRAESTRUTURA ---
  kafka:
    image: apache/kafka:3.7.0
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093,INTERNAL://:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,INTERNAL://kafka:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,INTERNAL:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
    networks:
      - net
    healthcheck:
      test: ["CMD-SHELL", "bash -c 'echo > /dev/tcp/localhost/9092' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  minio:
    image: minio/minio:latest
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
    networks:
      - net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3    

  message-store:
    image: scylladb/scylla:5.2
    container_name: message-store
    ports:
      - "9042:9042"
    healthcheck:
      test: ["CMD-SHELL", "cqlsh -e 'DESCRIBE KEYSPACES'"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 30s
    volumes:
      - scylla_data:/var/lib/scylla
    networks:
      - net

  metadata-db:
    container_name: metadata-db
    build:
      context: ../../services/metadata-service/database
      dockerfile: Dockerfile
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: ${METADATA_DB_NAME}
      POSTGRES_USER: ${METADATA_DB_USER}
      POSTGRES_PASSWORD: ${METADATA_DB_PASSWORD}
    volumes:
      - metadata_db_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d metadata_db -U metadata_user"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - net

  auth-db:
    image: postgres:15-alpine
    container_name: auth-db
    ports:
      - "5433:5432"
    environment:
      POSTGRES_DB: ${AUTH_DB_NAME}
      POSTGRES_USER: ${AUTH_DB_USER}
      POSTGRES_PASSWORD: ${AUTH_DB_PASSWORD}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${AUTH_DB_USER} -d auth_db"]
      interval: 5s
      timeout: 5s
      retries: 5
    volumes:
      - auth_db_data:/var/lib/postgresql/data # Volume dedicado
    networks:
      - net

  redis-cluster:
    image: grokzen/redis-cluster:7.0.0
    container_name: redis-cluster
    environment:
      - IP=172.28.0.10
      - INITIAL_PORT=7000
      - MASTERS=3
    ports:
      - "7000-7005:7000-7005" # Expõe portas dos nós
    healthcheck:
      test: ["CMD-SHELL", "redis-cli -p 7000 cluster info | grep -q 'cluster_state:ok' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      net:
        ipv4_address: 172.28.0.10

  gateway:
    image: nginx:latest
    container_name: gateway
    ports:
      - "80:80"
      - "8080:80"
    volumes:
      - ./gateway/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./client:/usr/share/nginx/html:ro
    depends_on:
      - api-service
      - delivery-worker
      - auth-service
      - minio
    networks:
      - net

  # --- MICROSSERVIÇOS ---

  api-service:
    container_name: api-service
    build:
      context: ../../
      dockerfile: common/Dockerfile.template
      args:
        SERVICE_NAME: api-service
        SERVICE_PORT: 8000
    command: uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS}
      - TOPIC_PRODUCE_MESSAGE=${TOPIC_MESSAGE_CREATED}
      - TOPIC_PRODUCE_STATUS=${TOPIC_MESSAGE_STATUS}
      - GRPC_METADATA_HOST=metadata-service:50051
      - S3_ENDPOINT_URL=http://minio:9000
      - S3_ACCESS_KEY=minioadmin
      - S3_SECRET_KEY=minioadmin
      - S3_BUCKET_NAME=chat-files
      - AUTH_SECRET_KEY=${AUTH_SECRET_KEY}
    depends_on:
      kafka:
        condition: service_healthy
      init-kafka:
        condition: service_completed_successfully
      metadata-service:
        condition: service_started
      message-store:
        condition: service_healthy
      minio:
        condition: service_healthy
    expose:
      - "8000"
    networks:
      - net

  auth-service:
    container_name: auth-service
    build:
      context: ../../
      dockerfile: common/Dockerfile.template
      args:
        SERVICE_NAME: auth-service
    command: uvicorn src.main:app --host 0.0.0.0 --port 8000
    environment:
      - PG_HOST=${AUTH_DB_HOST}
      - PG_DB=${AUTH_DB_NAME}
      - PG_USER=${AUTH_DB_USER}
      - PG_PASS=${AUTH_DB_PASSWORD}
      - AUTH_SECRET_KEY=${AUTH_SECRET_KEY}
      - PG_PORT=5432
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS}
      - TOPIC_USER_CREATED=${TOPIC_USER_CREATED}
    depends_on:
      auth-db:
        condition: service_healthy
      kafka:
        condition: service_healthy
      init-kafka:
        condition: service_completed_successfully
    expose:
      - "8000"
    networks:
      - net

  metadata-service:
    container_name: metadata-service
    build:
      context: ../../
      dockerfile: common/Dockerfile.template
      args:
        SERVICE_NAME: metadata-service
        SERVICE_PORT: 50051
    command: python -m src.main 
    ports:
      - "50051:50051"
    environment:
      - PG_HOST=${METADATA_DB_HOST}
      - PG_DB=${METADATA_DB_NAME}
      - PG_USER=${METADATA_DB_USER}
      - PG_PASS=${METADATA_DB_PASSWORD}
      - GRPC_PORT=50051
      - PG_PORT=5432
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS}
      - TOPIC_USER_CREATED=${TOPIC_USER_CREATED}
    depends_on:
      metadata-db:
        condition: service_healthy
      kafka:
        condition: service_healthy
      init-kafka:
        condition: service_completed_successfully
    networks:
      - net

  ingestion-service:
    container_name: ingestion-service
    build:
      context: ../../
      dockerfile: common/Dockerfile.template
      args:
        SERVICE_NAME: ingestion-service
    command: python -m src.main
    environment:
      - SCYLLA_HOST=message-store
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS}
      - KAFKA_GROUP_ID=${KAFKA_GROUP_INGESTION}
      - TOPIC_CONSUME=${TOPIC_MESSAGE_CREATED}
      - TOPIC_PRODUCE=${TOPIC_MESSAGE_STORED}
      - METADATA_HOST=metadata-service:50051
    depends_on:
      kafka:
        condition: service_healthy
      init-kafka:
        condition: service_completed_successfully
      message-store:
        condition: service_healthy
      metadata-service:
        condition: service_started
    networks:
      - net

  fanout-service:
    container_name: fanout-service
    build:
      context: ../../
      dockerfile: common/Dockerfile.template
      args:
        SERVICE_NAME: fanout-service
    command: python -m src.main
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS}
      - TOPIC_CONSUME=${TOPIC_MESSAGE_STORED}
      - TOPIC_PRODUCE_WHATSAPP=${TOPIC_CONNECTOR_WHATSAPP}
      - TOPIC_PRODUCE_DELIVERY=${TOPIC_MESSAGE_DELIVERY}
      - TOPIC_PRODUCE_INSTAGRAM=${TOPIC_CONNECTOR_INSTAGRAM}
      - METADATA_HOST=metadata-service:50051
      - KAFKA_GROUP_ID=${KAFKA_GROUP_FANOUT}
    depends_on:
      kafka:
        condition: service_healthy
      init-kafka:
        condition: service_completed_successfully
      metadata-service:
        condition: service_started
    networks:
      - net
  
  delivery-worker:
    container_name: delivery-worker
    build:
      context: ../../
      dockerfile: common/Dockerfile.template
      args:
        SERVICE_NAME: delivery-worker
    command: python -m src.main
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS}
      - REDIS_HOST=redis-cluster
      - SCYLLA_HOST=message-store
      - TOPIC_CONSUME=${TOPIC_MESSAGE_DELIVERY}
      - TOPIC_PRODUCE=${TOPIC_MESSAGE_NOTIFICATION}
      - KAFKA_GROUP_ID=delivery_worker_group
    depends_on:
      kafka:
        condition: service_healthy
      redis-cluster:
        condition: service_healthy
      message-store:
        condition: service_healthy
      init-kafka:
        condition: service_completed_successfully
    networks:
      - net

  socket-gateway:
    container_name: socket-gateway
    build:
      context: ../../
      dockerfile: common/Dockerfile.template
      args:
        SERVICE_NAME: socket-gateway
        SERVICE_PORT: 8000
    command: uvicorn src.main:app --host 0.0.0.0 --port 8000
    environment:
      - REDIS_HOST=redis-cluster
      - AUTH_SECRET_KEY=${AUTH_SECRET_KEY}
    depends_on:
      redis-cluster:
        condition: service_healthy
    expose:
      - "8000"
    networks:
      - net

  notification-service:
    container_name: notification-service
    build:
      context: ../../
      dockerfile: common/Dockerfile.template
      args:
        SERVICE_NAME: notification-service
    command: python -m src.main
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS}
      - TOPIC_CONSUME=${TOPIC_MESSAGE_NOTIFICATION}
      - KAFKA_GROUP_ID=notification_push_group
    depends_on:
      kafka:
        condition: service_healthy
      init-kafka:
        condition: service_completed_successfully
    networks:
      - net
  
  status-service:
    container_name: status-service
    build:
      context: ../../
      dockerfile: common/Dockerfile.template
      args:
        SERVICE_NAME: status-service
    command: python -m src.main
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS}
      - REDIS_HOST=redis-cluster
      - SCYLLA_HOST=message-store
      - TOPIC_CONSUME_STATUS=${TOPIC_MESSAGE_STATUS}
      - KAFKA_GROUP_ID=status_service_group
    depends_on:
      kafka:
        condition: service_healthy
      redis-cluster:
        condition: service_healthy
      message-store:
        condition: service_healthy
    networks:
      - net

  # --- MOCK CONNECTORS ---
  
  connector-whatsapp:
    container_name: connector-whatsapp
    build:
      context: ../../
      dockerfile: common/Dockerfile.template
      args:
        SERVICE_NAME: connector-mock
    command: uvicorn src.main:app --host 0.0.0.0 --port 8000
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS}
      - CHANNEL_NAME=whatsapp
      - TOPIC_CONSUME=${TOPIC_CONNECTOR_WHATSAPP}
      - TOPIC_STATUS=${TOPIC_MESSAGE_STATUS}
      - TOPIC_INBOUND=${TOPIC_MESSAGE_CREATED}
      - GRPC_AUTH_HOST=${AUTH_HOST}
    depends_on:
      kafka:
        condition: service_healthy
      init-kafka:
        condition: service_completed_successfully
      auth-service:
        condition: service_started
    networks:
      - net

  connector-instagram:
    container_name: connector-instagram
    build:
      context: ../../
      dockerfile: common/Dockerfile.template
      args:
        SERVICE_NAME: connector-mock
    command: uvicorn src.main:app --host 0.0.0.0 --port 8000
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS}
      - CHANNEL_NAME=instagram
      - TOPIC_CONSUME=${TOPIC_CONNECTOR_INSTAGRAM}
      - TOPIC_STATUS=${TOPIC_MESSAGE_STATUS}
      - TOPIC_INBOUND=${TOPIC_MESSAGE_CREATED}
      - GRPC_AUTH_HOST=${AUTH_HOST}
    depends_on:
      kafka:
        condition: service_healthy
      init-kafka:
        condition: service_completed_successfully
      auth-service:
        condition: service_started
    networks:
      - net

  # --- MONITORAMENTO ---

  dozzle:
    container_name: dozzle
    image: amir20/dozzle:latest
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "8888:8080"
    networks:
      - net

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8585:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - net
  
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    networks:
      - net

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    privileged: true 
    devices:
      - /dev/kmsg
    ports:
      - "8081:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    networks:
      - net  

  loki:
    image: grafana/loki:latest
    container_name: loki
    ports:
      - "3100:3100"
    volumes:
      - ./monitoring/loki-config.yaml:/etc/loki/local-config.yaml
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - net

  promtail:
    image: grafana/promtail:latest
    container_name: promtail
    volumes:
      - ./monitoring/promtail-config.yaml:/etc/promtail/config.yml
      - /var/run/docker.sock:/var/run/docker.sock
    command: -config.file=/etc/promtail/config.yml
    depends_on:
      - loki
    networks:
      - net

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_AUTH_ANONYMOUS_ENABLED=true
    depends_on:
      - prometheus
      - loki
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml
    networks:
      - net

  # --- INIT CONTAINERS ---
  init-kafka:
    image: apache/kafka:3.7.0
    container_name: init-kafka
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - net
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # Bloco de espera de segurança (garante que o broker esteja pronto para receber comandos)
      echo -e 'Aguardando Kafka estar pronto...'
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --list

      echo -e 'Criando tópicos kafka...'
      echo -e 'Config: Partitions=${KAFKA_TOPIC_PARTITIONS}, Replicas=${KAFKA_TOPIC_REPLICAS}'

      # Tópico 1: Message Created
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --create --if-not-exists --topic ${TOPIC_MESSAGE_CREATED} --partitions ${KAFKA_TOPIC_PARTITIONS} --replication-factor ${KAFKA_TOPIC_REPLICAS}
      
      # Tópico 2: Message Stored
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --create --if-not-exists --topic ${TOPIC_MESSAGE_STORED} --partitions ${KAFKA_TOPIC_PARTITIONS} --replication-factor ${KAFKA_TOPIC_REPLICAS}
      
      # Tópico 3: Message Status
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --create --if-not-exists --topic ${TOPIC_MESSAGE_STATUS} --partitions ${KAFKA_TOPIC_PARTITIONS} --replication-factor ${KAFKA_TOPIC_REPLICAS}
      
      # Tópico 4: Message Delivery
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --create --if-not-exists --topic ${TOPIC_MESSAGE_DELIVERY} --partitions ${KAFKA_TOPIC_PARTITIONS} --replication-factor ${KAFKA_TOPIC_REPLICAS}

      # Tópico 5: Connector Whatsapp
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --create --if-not-exists --topic ${TOPIC_CONNECTOR_WHATSAPP} --partitions ${KAFKA_TOPIC_PARTITIONS} --replication-factor ${KAFKA_TOPIC_REPLICAS}

      # Tópico 6: Connector Instagram
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --create --if-not-exists --topic ${TOPIC_CONNECTOR_INSTAGRAM} --partitions ${KAFKA_TOPIC_PARTITIONS} --replication-factor ${KAFKA_TOPIC_REPLICAS}

      # Tópico 7: User Created
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --create --if-not-exists --topic ${TOPIC_USER_CREATED} --partitions ${KAFKA_TOPIC_PARTITIONS} --replication-factor ${KAFKA_TOPIC_REPLICAS}

      # Tópico 8: Message Notification
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --create --if-not-exists --topic ${TOPIC_MESSAGE_NOTIFICATION} --partitions ${KAFKA_TOPIC_PARTITIONS} --replication-factor ${KAFKA_TOPIC_REPLICAS}

      echo -e 'Tópicos criados com sucesso: '
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --list
      "

volumes:
  kafka_data:
  grafana_data:
  scylla_data:
  minio_data:
  auth_db_data:
  metadata_db_data:

networks:
  net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16